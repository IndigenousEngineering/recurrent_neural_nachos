{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic cnn lstm model design\n",
    "\n",
    "CNN LSTM models have more than one specific type of a \"depth\" they bring to bear on a given problem.\n",
    "\n",
    "first, CNN LSTMs have a *depth of time*: think [back propogation through time (BPTT)](https://en.wikipedia.org/wiki/Backpropagation_through_time \"back propogation through time\") and/or [truncated back propogation through time (TBPTT)](https://r2rt.com/styles-of-truncated-backpropagation.html \"truncated back propogation through time\").\n",
    "\n",
    "CNN LSTM models also have a *depth of space*, with their multiple layers--convolutional, pooling, lstm etc--creating a deep, highly specialized and memory-persistent network.\n",
    "\n",
    ">*[CNN LSTMs are] a class of models that is both spatially and temporally deep,\n",
    "and has the flexibility to be applied to a variety of vision tasks involving sequential\n",
    "inputs and outputs*\n",
    ">\n",
    ">â€” Long-term Recurrent Convolutional Networks for Visual Recognition and Description, 2015\n",
    "\n",
    "in CNN LSTM architecture, convolutional neural networks act as encoders, effectively translating visual imagery into vector space--such that an LSTM RNN can effectively process it.\n",
    "\n",
    "CNNs \"in the wild\" (as it were) are usually designed to process a single image at a time. however, with a few adjustments they can provide effective [feature extraction](https://en.wikipedia.org/wiki/Feature_extraction \"feature extraction\") for visual time sequence data, like video.\n",
    "\n",
    "of course, time series problems are perfect for cells with longer-term \"memory\", like LSTMs.\n",
    "\n",
    "in this notebook, we'll use a visual time series problem--specifically, the task of classifying a simple video--to illustrate the `keras` api for CNN LSTM model design.\n",
    "\n",
    "#### two models working as one\n",
    "\n",
    "to build the model, we'll start by defining a convolutional neural network with 2D conv and max pooling layers--standard CNN stuff.\n",
    "\n",
    "we'll then use the `keras` `TimeDistributed()` wrapper to prepare the CNN to output series data that an LSTM expects.\n",
    "\n",
    "once our CNN is time-distributed, we can connect it to an LSTM and start classifying videos.\n",
    "\n",
    "## data\n",
    "\n",
    "this video prediction problem centers on the model's ability, given several frames of a line moving across a box, to properly classify which direction the line is moving in.\n",
    "\n",
    "the problem is contrived so that the data will be easy to generate (and also thus unlimited), but it does demonstrate the CNNs ability to encode & extract features from visual data, and the LSTM's ability to find some order (and retain that order) over the course of analyzing a sequence of information.\n",
    "\n",
    "*(python script for this data is from [jason brownlee's excellent course in LSTMs](www.machinelearningmastery.com), available at www.machinelearningmastery.com)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
