{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic cnn lstm model design\n",
    "\n",
    "CNN LSTM models have more than one specific type of a \"depth\" they bring to bear on a given problem.\n",
    "\n",
    "first, CNN LSTMs have a *depth of time*: think [back propogation through time (BPTT)](https://en.wikipedia.org/wiki/Backpropagation_through_time \"back propogation through time\") and/or [truncated back propogation through time (TBPTT)](https://r2rt.com/styles-of-truncated-backpropagation.html \"truncated back propogation through time\").\n",
    "\n",
    "CNN LSTM models also have a *depth of space*, with their multiple layers--convolutional, pooling, lstm etc--creating a deep, highly specialized and memory-persistent network.\n",
    "\n",
    ">*[CNN LSTMs are] a class of models that is both spatially and temporally deep,\n",
    "and has the flexibility to be applied to a variety of vision tasks involving sequential\n",
    "inputs and outputs*\n",
    ">\n",
    ">â€” Long-term Recurrent Convolutional Networks for Visual Recognition and Description, 2015\n",
    "\n",
    "in CNN LSTM architecture, convolutional neural networks act as encoders, effectively translating visual imagery into vector space--such that an LSTM RNN can effectively process it.\n",
    "\n",
    "CNNs \"in the wild\" (as it were) are usually designed to process a single image at a time. however, with a few adjustments they can provide effective [feature extraction](https://en.wikipedia.org/wiki/Feature_extraction \"feature extraction\") for visual time sequence data, like video.\n",
    "\n",
    "of course, time series problems are perfect for cells with longer-term \"memory\", like LSTMs.\n",
    "\n",
    "in this notebook, we'll use a visual time series problem--specifically, the task of classifying a simple video--to illustrate the `keras` api for CNN LSTM model design.\n",
    "\n",
    "#### two models working as one\n",
    "\n",
    "to build the model, we'll start by defining a convolutional neural network with 2D conv and max pooling layers--standard CNN stuff.\n",
    "\n",
    "we'll then use the `keras` `TimeDistributed()` wrapper to prepare the CNN to output series data that an LSTM expects.\n",
    "\n",
    "once our CNN is time-distributed, we can connect it to an LSTM and start classifying videos.\n",
    "\n",
    "## data\n",
    "\n",
    "this video prediction problem centers on the model's ability, given several frames of a line moving across a box, to properly classify which direction the line is moving in.\n",
    "\n",
    "the problem is contrived so that the data will be easy to generate (and also thus unlimited), but it does demonstrate the CNNs ability to encode & extract features from visual data, and the LSTM's ability to find some order (and retain that order) over the course of analyzing a sequence of information.\n",
    "\n",
    "*(python script to generate this data, with a few modifications, is from [jason brownlee's excellent course in LSTMs](www.machinelearningmastery.com), available at www.machinelearningmastery.com)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABPCAYAAADcB79hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAAhdJREFUeJzt3TFu6kAYhdHfUZZA6ngPsP8V4D2Q+rGHSZGSKWYiEa6fz5HoXIyu4JOFZFhaawXA6729+gAA/BBkgBCCDBBCkAFCCDJACEEGCCHIACEEGSCEIAOEEGSAEO8zF59Op7au65OOkuF2u9X9fl9Grz/CJlVV27bdW2sfI9fapO8Iu/j89I2+V6aCvK5rXa/X359qBy6Xy9T1R9ikqmpZlq/Ra23Sd4RdfH76Rt8rvrIACCHIACEEGSCEIAOEEGSAEIIMEEKQAUIIMkAIQQYIMfWkHrzasgw/lVtVVUf5V3W7PNrjJu6QAUIIMkAIQQYIIcgAIQQZIIQgA4QQZIAQggwQQpABQggyQAiPTv+xmcc5Ex7l/As26XvmLnvd/H/fxB0yQAhBBgghyAAhBBkghCADhBBkgBCCDBBCkAFCCDJACEEGCCHIACGmfsti27aI572T2OSRTfqSdknZfK+bzJx5hjtkgBCCDBBCkAFCCDJACEEGCCHIACEEGSCEIAOEEGSAEIIMEGIqyOfzuVprw68jsMkjm/TZ5dFeN5k588y53SEDhBBkgBCCDBBCkAFCCDJACEEGCCHIACEEGSCEIAOEEGSAEIIMEGKZ/Ovrf1X19bzjRPhsrX2MXnyQTaomdrFJ30F2sUnf0C5TQQbgeXxlARBCkAFCCDJACEEGCCHIACEEGSCEIAOEEGSAEIIMEOIbxDNhmCb+GtQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f91030908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import zeros\n",
    "from random import randint\n",
    "from random import random\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# generate the next frame in the sequence\n",
    "def next_frame(last_step, last_frame, column):\n",
    "    \n",
    "    # define the scope of the next step\n",
    "    lower = max(0, last_step-1)\n",
    "    upper = min(last_frame.shape[0]-1, last_step+1)\n",
    "    \n",
    "    # choose the row index for the next step\n",
    "    step = randint(lower, upper)\n",
    "    \n",
    "    # copy the prior frame\n",
    "    frame = last_frame.copy()\n",
    "    \n",
    "    # add the new step\n",
    "    frame[step, column] = 1\n",
    "    \n",
    "    return frame, step\n",
    "\n",
    "# generate a sequence of frames of a dot moving across an image\n",
    "def build_frames(size):\n",
    "    \n",
    "    frames = list()\n",
    "    \n",
    "    # create the first frame\n",
    "    frame = zeros((size,size))\n",
    "    \n",
    "    step = randint(0, size-1)\n",
    "\n",
    "    # decide if we are heading left or right\n",
    "    right = 1 if random() < 0.5 else 0\n",
    "    \n",
    "    col = 0 if right else size-1\n",
    "    \n",
    "    frame[step, col] = 1\n",
    "    \n",
    "    frames.append(frame)\n",
    "\n",
    "    # create all remaining frames\n",
    "    for i in range(1, size):\n",
    "        \n",
    "        col = i if right else size-1-i\n",
    "        \n",
    "        frame, step = next_frame(step, frame, col)\n",
    "        \n",
    "        frames.append(frame)\n",
    "    \n",
    "    return frames, right\n",
    "\n",
    "# generate sequence of frames\n",
    "size = 5\n",
    "\n",
    "frames, right = build_frames(size)\n",
    "\n",
    "# plot all frames\n",
    "pyplot.figure()\n",
    "\n",
    "for i in range(size):\n",
    "    \n",
    "    # create a gray scale subplot for each frame\n",
    "    pyplot.subplot(1, size, i+1)\n",
    "    \n",
    "    pyplot.imshow(frames[i], cmap='Greys')\n",
    "\n",
    "    # turn of the scale to make it clearer\n",
    "    ax = pyplot.gca()\n",
    "    \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    \n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the functions above, we can generate a pseudorandom sequence of images like these as many times as we want.\n",
    "\n",
    ">*it's worth noting here that many apparently [stochastic](https://en.wikipedia.org/wiki/Stochastic_process \"stochastic processes\") processes in fact follow predictable [distributions](https://en.wikipedia.org/wiki/Gaussian_process \"wikipedia: gaussian distribution\") and thus pseudorandom generation should be sufficient for our data purposes.*\n",
    "\n",
    "## preparing data for a 2d cnn\n",
    "\n",
    "a 2d convolutional neural network normally accepts data in 3 dimensions: *width, height,* and *channels*.\n",
    "\n",
    "our data has:\n",
    "\n",
    "* the __same width__ and __height__, equal to `size` in the data-generation function above\n",
    "\n",
    "* 1 __channel__ (greyscale)\n",
    "\n",
    "we can begin to define our 2d CNN input as `[size, size, 1]`.\n",
    "\n",
    "### multiple time steps as input to CNNs\n",
    "\n",
    "the vector `[size, size, 1]` would work for a single image fed into a cnn. however, we have *multiple images*, i.e. __multiple time steps__.\n",
    "\n",
    "on top of this, we have multiple instances (samples) of each set of time steps.\n",
    "\n",
    "__we need more dimensions__.\n",
    "\n",
    "adding time steps and samples as input dimensions gives us the vector `[n_samples, n_timesteps, size, size, 1]`.\n",
    "\n",
    "because the function above generates a number of timesteps equal to whatever the `size` variable is set to, __our version of this input shape is__\n",
    "> `[n_samples, size, size, size, 1]`\n",
    "\n",
    "with this in mind, it's easy to build a function that generates data for us, immediately reshaping it into a format suitable for multiple time steps as input to a cnn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_samples(size, n_samples):\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for sample in range(n_samples):\n",
    "        \n",
    "        frames, right = build_frames(size)\n",
    "        \n",
    "        # this is where our frames go\n",
    "        \n",
    "        X.append(frames)\n",
    "        \n",
    "        # vector of boolean values for right\n",
    "        \n",
    "        y.append(right)\n",
    "        \n",
    "    # reshape the data to fit cnn\n",
    "    # [n_samples, n_timesteps, width, height, channels]\n",
    "    # using numpy array().reshape()\n",
    "    \n",
    "    X = array(X).reshape(n_samples, size, size, size, 1)\n",
    "    \n",
    "    y = array(y).reshape(n_samples, 1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
