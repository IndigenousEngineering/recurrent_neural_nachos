{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic cnn lstm model design\n",
    "\n",
    "CNN LSTM models have more than one specific type of a \"depth\" they bring to bear on a given problem.\n",
    "\n",
    "first, CNN LSTMs have a *depth of time*: think [back propogation through time (BPTT)](https://en.wikipedia.org/wiki/Backpropagation_through_time \"back propogation through time\") and/or [truncated back propogation through time (TBPTT)](https://r2rt.com/styles-of-truncated-backpropagation.html \"truncated back propogation through time\").\n",
    "\n",
    "CNN LSTM models also have a *depth of space*, with their multiple layers--convolutional, pooling, flattening, lstm etc--creating a deep, highly specialized and memory-persistent network.\n",
    "\n",
    ">*[CNN LSTMs are] a class of models that is both spatially and temporally deep,\n",
    "and has the flexibility to be applied to a variety of vision tasks involving sequential\n",
    "inputs and outputs*\n",
    ">\n",
    ">â€” Long-term Recurrent Convolutional Networks for Visual Recognition and Description, 2015\n",
    "\n",
    "in CNN LSTM architecture, convolutional neural networks act as encoders, effectively translating visual imagery into vector space--such that an LSTM RNN can effectively process it.\n",
    "\n",
    "CNNs \"in the wild\" (as it were) are usually designed to process a single image at a time. however, with a few adjustments they can provide effective [feature extraction](https://en.wikipedia.org/wiki/Feature_extraction \"feature extraction\") for visual time sequence data, like video.\n",
    "\n",
    "of course, time series problems are perfect for cells with longer-term \"memory\", like LSTMs.\n",
    "\n",
    "in this notebook, we'll use a visual time series problem--specifically, the task of classifying a simple video--to illustrate the `keras` api for CNN LSTM model design.\n",
    "\n",
    "#### two models working as one\n",
    "\n",
    "to build the model, we'll start by defining a convolutional neural network with 2D conv and max pooling layers--standard CNN stuff.\n",
    "\n",
    "we'll then use the `keras` `TimeDistributed()` wrapper to prepare the CNN to output series data that an LSTM expects.\n",
    "\n",
    "once our CNN is time-distributed, we can connect it to an LSTM and start classifying videos.\n",
    "\n",
    "## data\n",
    "\n",
    "this video prediction problem centers on the model's ability, given several frames of a line moving across a box, to properly classify which direction the line is moving in.\n",
    "\n",
    "the problem is contrived so that the data will be easy to generate (and also thus unlimited), but it does demonstrate the CNNs ability to encode & extract features from visual data, and the LSTM's ability to find some order (and retain that order) over the course of analyzing a sequence of information.\n",
    "\n",
    "*(python script to generate this data, with a few modifications, is from [jason brownlee's excellent course in LSTMs](www.machinelearningmastery.com), available at www.machinelearningmastery.com)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABPCAYAAADcB79hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAAgxJREFUeJzt3bFtwzAURVEqyAhOHe1g7z+BNUTqZAemSKuCv2D8bJ5Ts6C/pQvBAK2t994AeLy3R28AgD+CDBBCkAFCCDJACEEGCCHIACEEGSCEIAOEEGSAEIIMEOK9svhyufR93ydtZZ7jOErre+/b6NpVZtJa++m9f4wsNJNzq8zF/XNq6FopBXnf93a/36sbebhtG74+yhaaydfoQjM5t9Bchi00k6FrxU8WACEEGSCEIAOEEGSAEIIMEEKQAUIIMkAIQQYIIcgAIUon9Z5V5c3at9tt4k7mqpweqr5tfOZprZnM5NysuVTvn+M4pn5HFQnXiidkgBCCDBBCkAFCCDJACEEGCCHIACEEGSCEIAOEEGSAEIIMEGKJo9OrmHmsNEX1uPIzz2Tm0eyUuVyv19JLTl99Jp6QAUIIMkAIQQYIIcgAIQQZIIQgA4QQZIAQggwQQpABQggyQAhBBgjhvyx4Kgn/N/BfVvqso159Jp6QAUIIMkAIQQYIIcgAIQQZIIQgA4QQZIAQggwQQpABQggyQAhBBgghyAAhBBkghCADhBBkgBCCDBBCkAFCCDJACEEGCCHIACEEGSCEIAOE2Cqv1d627bu19jVvOxE+e+8fo4sXmUlrhbmYyblF5mIm54bmUgoyAPP4yQIghCADhBBkgBCCDBBCkAFCCDJACEEGCCHIACEEGSDEL4M1hrnXTNhOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feda7b2d400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import zeros\n",
    "from random import randint\n",
    "from random import random\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# generate the next frame in the sequence\n",
    "def next_frame(last_step, last_frame, column):\n",
    "    \n",
    "    # define the scope of the next step\n",
    "    lower = max(0, last_step-1)\n",
    "    upper = min(last_frame.shape[0]-1, last_step+1)\n",
    "    \n",
    "    # choose the row index for the next step\n",
    "    step = randint(lower, upper)\n",
    "    \n",
    "    # copy the prior frame\n",
    "    frame = last_frame.copy()\n",
    "    \n",
    "    # add the new step\n",
    "    frame[step, column] = 1\n",
    "    \n",
    "    return frame, step\n",
    "\n",
    "# generate a sequence of frames of a dot moving across an image\n",
    "def build_frames(size):\n",
    "    \n",
    "    frames = list()\n",
    "    \n",
    "    # create the first frame\n",
    "    frame = zeros((size,size))\n",
    "    \n",
    "    step = randint(0, size-1)\n",
    "\n",
    "    # decide if we are heading left or right\n",
    "    right = 1 if random() < 0.5 else 0\n",
    "    \n",
    "    col = 0 if right else size-1\n",
    "    \n",
    "    frame[step, col] = 1\n",
    "    \n",
    "    frames.append(frame)\n",
    "\n",
    "    # create all remaining frames\n",
    "    for i in range(1, size):\n",
    "        \n",
    "        col = i if right else size-1-i\n",
    "        \n",
    "        frame, step = next_frame(step, frame, col)\n",
    "        \n",
    "        frames.append(frame)\n",
    "    \n",
    "    return frames, right\n",
    "\n",
    "# generate sequence of frames\n",
    "size = 5\n",
    "\n",
    "frames, right = build_frames(size)\n",
    "\n",
    "# plot all frames\n",
    "pyplot.figure()\n",
    "\n",
    "for i in range(size):\n",
    "    \n",
    "    # create a gray scale subplot for each frame\n",
    "    pyplot.subplot(1, size, i+1)\n",
    "    \n",
    "    pyplot.imshow(frames[i], cmap='Greys')\n",
    "\n",
    "    # turn of the scale to make it clearer\n",
    "    ax = pyplot.gca()\n",
    "    \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    \n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with the functions above, we can generate a pseudorandom sequence of images like these as many times as we want.\n",
    "\n",
    ">*it's worth noting here that many apparently [stochastic](https://en.wikipedia.org/wiki/Stochastic_process \"stochastic processes\") processes in fact follow predictable [distributions](https://en.wikipedia.org/wiki/Gaussian_process \"wikipedia: gaussian distribution\") and thus pseudorandom generation should be sufficient for our data purposes.*\n",
    "\n",
    "## preparing data for a 2d cnn\n",
    "\n",
    "a 2d convolutional neural network normally accepts data in 3 dimensions: *width, height,* and *channels*.\n",
    "\n",
    "our data has:\n",
    "\n",
    "* the __same width__ and __height__, equal to `size` in the data-generation function above\n",
    "\n",
    "* 1 __channel__ (greyscale)\n",
    "\n",
    "we can begin to define our 2d CNN input as `[size, size, 1]`.\n",
    "\n",
    "### multiple time steps as input to CNNs\n",
    "\n",
    "the vector `[size, size, 1]` would work for a single image fed into a cnn. however, we have *multiple images*, i.e. __multiple time steps__.\n",
    "\n",
    "on top of this, we have multiple instances (samples) of each set of time steps.\n",
    "\n",
    "__we need more dimensions__.\n",
    "\n",
    "adding time steps and samples as input dimensions gives us the vector `[n_samples, n_timesteps, size, size, 1]`.\n",
    "\n",
    "because the function above generates a number of timesteps equal to whatever the `size` variable is set to, __our version of this input shape is__\n",
    "> `[n_samples, size, size, size, 1]`\n",
    "\n",
    "with this in mind, it's easy to build a function that generates data for us, immediately reshaping it into a format suitable for multiple time steps as input to a cnn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_samples(size, n_samples):\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for sample in range(n_samples):\n",
    "        \n",
    "        frames, right = build_frames(size)\n",
    "        \n",
    "        # this is where our frames go\n",
    "        \n",
    "        X.append(frames)\n",
    "        \n",
    "        # vector of boolean values for right\n",
    "        \n",
    "        y.append(right)\n",
    "        \n",
    "    # reshape the data to fit cnn\n",
    "    # [n_samples, n_timesteps, width, height, channels]\n",
    "    # using numpy array().reshape()\n",
    "    \n",
    "    X = np.array(X).reshape(n_samples, size, size, size, 1)\n",
    "    \n",
    "    y = np.array(y).reshape(n_samples, 1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `make_samples()` function will generate as many samples of whatever size we need, making a typical *train test split* (a method of reserving data from training to be tested on sight unseen) unnecessary.\n",
    "\n",
    "## define & compile\n",
    "\n",
    "in modeling terms, the difficulty of the problem depends on the size of the images being analyzed. \n",
    "\n",
    "a 50-pixel by 50-pixel image is a moderately difficult problem for this model to learn. we'll set `size` equal to 50.\n",
    "\n",
    "### components of the cnn model\n",
    "\n",
    "our cnn model is effectively an encoder/feature extractor for our lstm model.\n",
    "\n",
    "we will be using `Conv2D` layers wrapped in `TimeDistributed` layers to allow for processing multiple time steps. we will use 2 filters, and a small 2x2 kernel for reading in the image data. our activation function will be [rectified linear units](https://en.wikipedia.org/wiki/Rectifier_(neural_networks) \"wikipedia: relu\"), aka `relu`.\n",
    "\n",
    "after our `Conv2D` layers, we'll define a `MaxPooling2D` layer (as is typical for CNNs) that will cut the `Conv2D` layer's two 49-pixel-by-49-pixel outputs in half, to a vector of `[24, 24, 2]`.\n",
    "\n",
    "finally, the `Flatten` layer will transform `MaxPoolingLayer`'s `[24, 24, 2]` vector down to a single-dimension vector with 1,152 elements.\n",
    "\n",
    "> *while* `MaxPooling2D` *outputs a 3-dimensional* `[24, 24, 2]` *vector, the* `Flatten` *layer compresses it down to a 1-dimensional vector with* `24 * 24 * 2 = 1,152` *elements: hence the name \"flatten\".*\n",
    "\n",
    "### components of the lstm model\n",
    "\n",
    "#### input:\n",
    "\n",
    "our lstm model will consist of \n",
    "\n",
    "* __1 layer__, with \n",
    "\n",
    "* __50 cells__\n",
    "\n",
    "recall that the cnn model is wrapped in a `TimeDistributed` layer to allow for multiple time steps. also recall that the `Flatten` layer takes earlier convolutional and pooling layer inputs, and flattens them down to a 1d, 1,152-element vector.\n",
    "\n",
    "what this means in practical terms for our lstm: __for each sample, the lstm model will see__\n",
    "\n",
    "* __50 time steps__, each having a 1d vector of\n",
    "\n",
    "* __1,152 values__\n",
    "\n",
    "#### output:\n",
    "\n",
    "since this is a binary classification problem, we only need one neuron for our `Dense` output layer.\n",
    "\n",
    "#### configuration:\n",
    "\n",
    "we're down to the final configuration details.\n",
    "\n",
    "for this problem, our model will use:\n",
    "\n",
    "* a [__sigmoid activation function__](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6 \"towards data science: activation functions\")\n",
    "* [__logarithmic loss__](http://wiki.fast.ai/index.php/Log_Loss \"fast ai log loss wiki\") (ie `binary_crossentropy`), minimized using\n",
    "* [__adam gradient descent__](https://arxiv.org/abs/1412.6980 \"arxiv: adam gradient descent\") optimizer\n",
    "\n",
    "lastly, we'll compile our model with instructions to report the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, None, 49, 49, 2)   10        \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 24, 24, 2)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 1152)        0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                240600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 240,661\n",
      "Trainable params: 240,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# we're building a Sequential model, with\n",
    "# lots of different types of layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# define the problem\n",
    "\n",
    "size = 50\n",
    "\n",
    "# define the model\n",
    "\n",
    "cnn_lstm_model = Sequential()\n",
    "\n",
    "# add 1st (and in this case only) Conv2D layer\n",
    "# wrap in TimeDistributed() layer\n",
    "\n",
    "cnn_lstm_model.add(TimeDistributed\n",
    "                   (Conv2D(2, (2,2), activation='relu'), \n",
    "                    input_shape=(None, size, size, 1)))\n",
    "\n",
    "# MaxPooling layer, also wrapped in TimeDistributed\n",
    "\n",
    "cnn_lstm_model.add(TimeDistributed\n",
    "                  (MaxPooling2D(pool_size=(2, 2))))\n",
    "\n",
    "# Flatten layer, wrapped in TimeDistributed\n",
    "\n",
    "cnn_lstm_model.add(TimeDistributed\n",
    "                  (Flatten()))\n",
    "\n",
    "# lstm layer with 50 memory cells\n",
    "\n",
    "cnn_lstm_model.add(LSTM(50))\n",
    "\n",
    "# dense output layer with sigmoid activation funtion\n",
    "\n",
    "cnn_lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile with log loss & adam SGD optimizer\n",
    "\n",
    "cnn_lstm_model.compile(loss='binary_crossentropy', \n",
    "                      optimizer='adam', metrics=['acc'])\n",
    "\n",
    "stats = cnn_lstm_model.summary()\n",
    "\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model sumamry confirms the shape of each of our layers. \n",
    "\n",
    "in total, our model has 240,661 parameters.\n",
    "\n",
    "*note: when i originally ran this cell, i forgot to specify the* `size` *variable--the only clue was that the model summary showed i had far too few parameters for a model this size. printing out & carefully reviewing stats ftw!*\n",
    "\n",
    "## fit the model\n",
    "\n",
    "##### design note: there are a couple of frameworks we can use to train a model, in general.\n",
    "\n",
    "on one hand, we can train the model using a smaller dataset with a large number of epochs. this is certainly a solid option when data is limited.\n",
    "\n",
    "optimally, however, it is better to train any model using a large number of unique samples, in one big epoch. in contrast to the first potential method, the model will (in general) see each sample only once, instead of multiple times.\n",
    "\n",
    "this helps keep the model from memorizing the data--in other words, overfitting (and thus being poorly generalizable, if at all).\n",
    "\n",
    "because we can generate as much or little data as we need, we will choose the second method here. we'll generate a *large number of __samples__*, and allow our model to see each one once: training on the dataset for *one __epoch__*.\n",
    "\n",
    "for speedier training, we'll set the *__batch_size__* (number of samples between back propogation weight updates) to 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4000/4000 [==============================] - 29s 7ms/step - loss: 0.2154 - acc: 0.8955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed33b679e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate data\n",
    "\n",
    "X, y = make_samples(size, 4000)\n",
    "\n",
    "# fit the model\n",
    "\n",
    "cnn_lstm_model.fit(X, y, batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in-model stats\n",
    "\n",
    "on this run, our model took approximately 29 seconds to train on 4,000 samples, with a __loss__ of 0.2154 and an __accuracy__ of 0.8955.\n",
    "\n",
    "because neural nets are stochastic, a different run of the same code will likely produce *slightly* different results. however, these metrics are still useful for comparing models.\n",
    "\n",
    "##### a quick note re: memory errors\n",
    "\n",
    "*because the dataset is generated and stored in local memory, it's possible to run out of ram and receive a nice python `Memory Error`. if this happens while running the code, simply reduce the number of samples.*\n",
    "\n",
    "*further note: obviously it's better to train on more samples. so keep in mind that reducing the number may affect model performance!*\n",
    "\n",
    "## model evaluation\n",
    "\n",
    "we'll use two methods to evaluate our model here.\n",
    "\n",
    "first, we'll test the model on unseen data--an essential part of understanding whether our model can generalize.\n",
    "\n",
    "second, we'll use the model to make a prediction, and see how it looks.\n",
    "\n",
    "### loss and accuracy on unseen data\n",
    "\n",
    "to get an idea of the model's ability to generalize, we can create a new set of samples and ask the model to make predictions on these.\n",
    "\n",
    "we'll use `evaluate()` to retrieve the model's performance metrics on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loss: 0.010724, model accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# create new, unseen data\n",
    "\n",
    "X, y = make_samples(size, 100)\n",
    "\n",
    "# get metrics\n",
    "\n",
    "loss, accuracy = cnn_lstm_model.evaluate(X, y, verbose=0)\n",
    "\n",
    "# display loss & accuracy converted to percentage\n",
    "\n",
    "print('model loss: %f, model accuracy: %f' % (loss, accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing an individual prediction\n",
    "\n",
    "lastly, we'll generate a single random sequence and ask the model to make a prediction of whether the line is moving left or right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction: right\n",
      "actual: right\n"
     ]
    }
   ],
   "source": [
    "# create new data: a single sample\n",
    "\n",
    "X, y = make_samples(size, 1)\n",
    "\n",
    "# get predictions\n",
    "\n",
    "y_hat = cnn_lstm_model.predict_classes(X, verbose=0)\n",
    "\n",
    "# store prediction & actual for display\n",
    "\n",
    "prediction = 'right' if y_hat[0] == 1 else 'left'\n",
    "\n",
    "actual = 'right' if y[0] == 1 else 'left'\n",
    "\n",
    "# diplay results\n",
    "\n",
    "print('model prediction: %s' '\\n' 'actual: %s' % (prediction, actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cool! our model works.\n",
    "\n",
    "## thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
